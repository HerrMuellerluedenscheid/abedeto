#!/usr/bin/env python
import os
import errno
import logging
import sys
import matplotlib.pyplot as plt
import glob

from pyrocko import util
from pyrocko import model
from pyrocko import io
from pyrocko import trace
from pyrocko import crust2x2
from pyrocko.io_common import FileLoadError
from pyrocko.guts import Object, Dict, String, List, load as guts_load
from pyrocko.gf.store import remake_dir, CannotCreate
from pyrocko import orthodrome as ortho
from pyrocko.fdsn import station as wsstation

import abedeto.store_creator as store_creator
from abedeto.beam_stack import BeamForming
from abedeto.map import MapParameters, make_map
from abedeto.request import DataProvider, CakeTiming


pjoin = os.path.join
logger = logging.getLogger("run")

output_units = "M"
stores_superdir = "stores"
array_data = "array_data"
_event_fn = "event.pf"
event_fn = "event.pf"
km = 1000.0
_fn_data_provider = "request.yaml"
_crust = crust2x2.Crust2()
_profile_keys = crust2x2.get_profile_keys()


class StoreMapper(Object):
    mapping = Dict.T(String.T(), List.T(String.T()))

    def __getitem__(self, key):
        return self.mapping[key]


def one_or_error(items):
    e = list(items)
    if len(e) > 1:
        raise Exception("more than one item in list. Can only handle one")
    return e[0]


def dictify_resps(respfiles):
    out = {}
    for r in respfiles:
        resp = wsstation.Response.load(filename=r)
        r = r.split("/")[-1]
        r = r.replace("resp_", "")
        r = r.replace(".yaml", "")
        out[tuple(r.split("."))] = resp
    return out


def restitute(traces, respfiles, freqlimits, tfade):
    """Restitute"""
    restituted = []
    responses = dictify_resps(respfiles)
    for tr in traces:
        if tr.nslc_id not in responses:
            logger.warn(
                'No Response information for %s found. run "abedeto download --get-response"'
                % ".".join(tr.nslc_id)
            )
            continue

        response = responses[tr.nslc_id]
        tr = tr.transfer(tfade, freqlimits, transfer_function=response, invert=True)
        restituted.append(tr)

    return restituted


def one_2_list(items):
    if not isinstance(items, list):
        return [items]


def init(args):
    if args.format == "catalog":
        events = list(model.Event.load_catalog(args.events))

    elif args.format == "yaml":
        events = guts_load(filename=args.events)
        if not isinstance(events, list):
            events = [events]

    if len(events) == 0:
        logger.warn("no events found")
        sys.exit(0)

    if args.name and len(events) > 1:
        logger.warn(
            "Cannot use defined name if list of events. Will" " use event names instead"
        )
    for i_e, e in enumerate(events):
        if args.name is not None:
            name = args.name
            e.name = name
        elif e.name:
            name = e.name
        else:
            logger.warn("event name is empty. Skipping...")
            continue
        remake_dir(name, args.force)
        remake_dir(pjoin(name, stores_superdir), args.force)

        model.Event.dump_catalog([e], pjoin(name, event_fn))
        if args.download:
            download(args, event=e, prefix=name)
        logger.info("." * 30)
        logger.info("Prepared project directory %s for you" % name)


def download(args, event=None, prefix=""):
    if isinstance(args.projects, list):
        fns = args.projects
    else:
        fns = ["."]

    for event_dir in fns:
        try:
            event = list(model.Event.load_catalog(pjoin(event_dir, event_fn)))
        except IOError as e:
            if e.errno == errno.ENOTDIR:
                logger.debug(e)
                continue
            raise e

        assert len(event) == 1
        event = event[0]

        if not event:
            event = model.Event.load_catalog(event_fn)
            event = one_or_error(event)
        extra_kw = {
            "get_responses": args.get_responses,
            "want": args.want.split(","),
            "force": args.force,
            "event": event,
        }
        get_responses = args.get_responses
        fn_data_provider = pjoin(event_dir, _fn_data_provider)
        if os.path.isfile(fn_data_provider):
            provider = DataProvider.load(filename=fn_data_provider)
        else:
            provider = DataProvider()

        try:
            settings = args.download_settings
            provider.download(settings=settings, **extra_kw)
        except (AttributeError, TypeError):
            tmin = CakeTiming(
                phase_selection="first(p|P|PP|P(cmb)P(icb)P(icb)p(cmb)p)-20",
                fallback_time=100.0,
            )
            tmax = CakeTiming(
                phase_selection="first(p|P|PP|P(cmb)P(icb)P(icb)p(cmb)p)+40",
                fallback_time=600.0,
            )
            provider.download(
                timing=(tmin, tmax), prefix=pjoin(event_dir, prefix), **extra_kw
            )

        provider.dump(filename=fn_data_provider)


def beam(args):
    """Uses tmin timing object, without the offset to calculate the beam"""
    if isinstance(args.projects, list):
        fns = args.projects
    else:
        fns = ["."]

    for event_dir in fns:
        logger.info(event_dir)
        event = list(model.Event.load_catalog(pjoin(event_dir, event_fn)))
        assert len(event) == 1
        event = event[0]
        provider = DataProvider.load(filename=pjoin(event_dir, _fn_data_provider))
        array_centers = []
        for array_id in provider.use:
            directory = pjoin(event_dir, array_data, array_id)
            traces = io.load(pjoin(directory, "traces.mseed"))
            stations = model.load_stations(pjoin(directory, "stations.pf"))
            if args.restitute:
                resp_files = glob.glob(pjoin(directory, "responses/*"))
                ftap = list(map(float, args.freqlimits.split(":")))
                traces = restitute(traces, resp_files, ftap, args.fade)
                if len(traces) == 0:
                    continue
            bf = BeamForming(stations, traces, normalize=args.normalize)
            bf.process(
                event=event,
                timing=provider.timings[array_id].timings[0],
                fn_dump_center=pjoin(directory, "array_center.pf"),
                fn_beam=pjoin(directory, "beam.mseed"),
                station=array_id,
            )
            if args.plot:
                bf.plot(fn=pjoin(directory, "beam_shifts.png"))

            array_centers.append(bf.station_c)


def propose_stores(args):
    from abedeto.get_bounds import get_bounds

    if isinstance(args.projects, list):
        fns = args.projects
    else:
        fns = ["."]

    events = []
    stations = []

    store_mapper = StoreMapper()
    # basics fine
    depths = args.depths.split(":")
    sdmin, sdmax, sddelta = map(lambda x: float(x), depths)
    store_kwargs = {
        "superdir": args.store_dir,
        "source_depth_min": sdmin,
        "source_depth_max": sdmax,
        "source_depth_delta": sddelta,
        "sample_rate": args.sample_rate,
        "force": args.force,
        "run_ttt": args.ttt,
        "force": args.force,
        "simplify": args.simplify,
        "distance_delta_max": args.dmax,
    }

    for event_dir in fns:
        event_fn = pjoin(event_dir, _event_fn)
        try:
            events.extend(list(model.Event.load_catalog(event_fn)))
        except IOError as e:
            if e.errno == errno.ENOENT:
                logger.debug("no file %s" % e)
            elif e.errno == errno.ENOTDIR:
                logger.debug(e)
                continue
            else:
                raise e

        try:
            provider = DataProvider.load(filename=pjoin(event_dir, _fn_data_provider))
        except IOError as e:
            if e.errno == errno.ENOENT:
                logger.debug("no file %s" % e)
            else:
                raise e

        for array_id in provider.use:
            directory = pjoin(event_dir, array_data, array_id)
            try:
                stations.extend(
                    model.load_stations(pjoin(directory, "array_center.pf"))
                )
            except IOError as e:
                if e.errno == errno.ENOENT:
                    logger.debug("no file %s" % e)
                else:
                    raise e

            # store_mapper.mapping[array_id] = configids

        store_mapper.dump(filename=pjoin(event_dir, "store_mapping.yaml"))
    distances, models = store_creator.setup_distances_crusts(stations, events)
    config_ids = store_creator.propose_stores(distances, models, **store_kwargs)
    #     configids = store_creator.propose_store(station, **store_kwargs)

    #
    # provider = DataProvider.load(filename=_fn_data_provider)
    #     for array_id in provider.use:
    #         directory = pjoin(array_data, array_id)
    #         fn_array_center = pjoin(directory, 'array_center.pf')
    #         if not os.path.isfile(fn_array_center):
    #             logger.error("No such file: %s. Probably, you need to run 'abedeto beam', first." % fn_array_center)
    #             return
    #         station = model.load_stations(fn_array_center)
    #         station = one_or_error(station)


def get_profile_key(location):
    return crust2x2.get_profile(location.lat, location.lon)._ident


def process(args):
    from abedeto.guesstimate_depth_v02 import PlotSettings, plot

    if isinstance(args.projects, list):
        fns = args.projects
    else:
        fns = ["."]

    for event_dir in fns:
        provider = DataProvider.load(filename=pjoin(event_dir, _fn_data_provider))
        if args.array_id:
            array_ids = [args.array_id]
        else:
            array_ids = provider.use

        # store_mapping = StoreMapper.load(filename=pjoin(event_dir,
        #'store_mapping.yaml'))
        event = one_or_error(list(model.Event.load_catalog(pjoin(event_dir, event_fn))))
        source_crust = get_profile_key(event)
        for array_id in array_ids:
            subdir = pjoin(event_dir, array_data, array_id)
            settings_fn = pjoin(subdir, "plot_settings.yaml")
            if os.path.isfile(settings_fn) and args.overwrite_settings:
                settings = PlotSettings.load(filename=pjoin(settings_fn))
                settings.update_from_args(args)
            else:
                settings = PlotSettings.from_argument_parser(args)

            if not settings.trace_filename:
                settings.trace_filename = pjoin(subdir, "beam.mseed")
            if not settings.station_filename:
                fn_array_center = pjoin(subdir, "array_center.pf")
                settings.station_filename = fn_array_center
                station = model.load_stations(fn_array_center)
                station = one_or_error(station)
                target_crust = get_profile_key(station)

            # if not settings.store_id:
            #    if len(store_mapping[array_id])>1:
            #        logging.exception(Exception('Found several store_ids for %s. Use'
            #                ' --array_id=STORE_ID to excplicitly set store' % array_id))
            # else:
            settings.store_id = "%s_%s_%s" % (array_id, target_crust, source_crust)
            settings.event_filename = pjoin(event_dir, event_fn)
            settings.save_as = pjoin(event_dir, "depth_%(array-id)s.png")
            plot(settings)
            if args.overwrite_settings:
                settings.dump(filename=settings_fn)
        if args.show:
            plt.show()


def mapify(args):
    provider = DataProvider.load(filename=_fn_data_provider)
    stations = []
    for array_id in provider.use:
        subdir = pjoin(array_data, array_id)
        stations.append(
            one_or_error(model.load_stations(pjoin(subdir, "array_center.pf")))
        )
    event = one_or_error(list(model.Event.load_catalog(event_fn)))
    dists = map(lambda x: ortho.distance_accurate50m(event, x), stations)
    params = MapParameters(
        stations=stations,
        events=[event],
        lon=event.lon,
        lat=event.lat,
        radius=max(dists) * 0.9,
        show_topo=args.show_topo,
        show_grid=False,
    )
    make_map(map_parameters=params)


def try_ENOENT(f, kwargs=None):
    try:
        return f(**kwargs)
    except IOError as e:
        if e.errno == errno.ENOENT:
            logger.debug("no file %s" % e)
        else:
            raise e


def snuffle(args):
    """Uses tmin timing object, without the offset to calculate the beam"""
    if isinstance(args.projects, list):
        fns = args.projects
    else:
        fns = ["."]

    events = []
    traces = []
    stations = []
    for event_dir in fns:
        event_fn = pjoin(event_dir, _event_fn)
        try:
            events.extend(list(model.Event.load_catalog(event_fn)))
        except IOError as e:
            if e.errno == errno.ENOENT:
                logger.debug("no file %s" % e)
            elif e.errno == errno.ENOTDIR:
                logger.debug(e)
                continue
            else:
                raise e
        fn_data_provider = pjoin(event_dir, _fn_data_provider)
        provider = try_ENOENT(DataProvider.load, kwargs={"filename": fn_data_provider})
        if provider is None:
            logger.debug("no provider %s" % fn_data_provider)
            continue

        for array_id in provider.use:
            directory = pjoin(event_dir, array_data, array_id)
            fn_beam = pjoin(directory, "beam.mseed")
            try:
                traces.extend(io.load(pjoin(directory, "traces.mseed")))
            except FileLoadError:
                logger.debug("no file %s" % fn_beam)
                pass

            try:
                traces.extend(io.load(fn_beam))
            except FileLoadError:
                logger.debug("no file %s" % fn_beam)
                pass

            try:
                stations.extend(model.load_stations(pjoin(directory, "stations.pf")))
            except IOError as e:
                if e.errno == errno.ENOENT:
                    logger.debug("no file %s" % e)
                else:
                    raise e
            try:
                stations.extend(
                    model.load_stations(pjoin(directory, "array_center.pf"))
                )
            except IOError as e:
                if e.errno == errno.ENOENT:
                    logger.debug("no file %s" % e)
                else:
                    raise e
    stations = list(set(stations))
    trace.snuffle(traces, stations=stations, events=events)


def get_bounds(args):
    from abedeto.get_bounds import get_bounds as gb

    e = list(model.Event.load_catalog(args.events))
    directory = pjoin("array_data", args.array_id)
    stations = model.load_stations(pjoin(directory, "array_center.pf"))
    gb(stations, events=e, show_fig=True, km=True)


def dq(x):
    # return '"%s"' % x
    return x


def ldq(xs):
    return ', '.join(dq(x) for x in xs)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        "abedeto",
        description="What was the depth, again?",
        add_help=True)

    loglevel_choices = ["critical", "error", "warning", "info", "debug"]
    loglevel_default = "info"

    parser.add_argument(
        '--log',
        choices=loglevel_choices,
        default=loglevel_default,
        metavar='LEVEL',
        help='set logger level. Choices: %s. Default: %s.' % (
            ldq(loglevel_choices), dq(loglevel_default)))

    sp = parser.add_subparsers(dest="cmd")
    init_parser = sp.add_parser("init", help="Create a new project")
    init_parser.add_argument("events", help="Event you don't know the depth of")
    init_parser.add_argument("--name", help="name", default=None)
    init_parser.add_argument(
        "--download",
        action="store_true",
        default=False,
        help="download available data right away.",
    )
    init_parser.add_argument(
        "--force", action="store_true", default=True, help="force overwrite"
    )
    init_parser.add_argument(
        "--format",
        default="catalog",
        choices=["yaml", "catalog", ""],
        help="[yaml|catalog], default catalog",
    )

    download_parser = sp.add_parser("download", help="Download data")
    download_parser.add_argument(
        "projects", help='default "all available"', nargs="*", default="."
    )
    download_parser.add_argument(
        "--array-id", help="only download for this array", dest="want", default="all"
    )
    download_parser.add_argument(
        "--settings",
        help="Load download settings.",
        dest="download_settings",
        default=False,
    )
    download_parser.add_argument(
        "--get-responses",
        action="store_true",
        default=False,
        dest="get_responses",
        help="get station meta infos",
    )
    download_parser.add_argument(
        "--force", action="store_true", default=False, help="force overwrite"
    )

    beam_parser = sp.add_parser("beam", help="Beam forming")
    beam_parser.add_argument(
        "projects", help='default "all available"', nargs="*", default="."
    )
    beam_parser.add_argument(
        "--map_filename", help="filename of map", default="map.png"
    )
    beam_parser.add_argument(
        "--normalize",
        help="normlize by standard deviation of trace",
        action="store_true",
        default=True,
    )
    beam_parser.add_argument(
        "--restitute",
        help="requires --get-responses when downloading. "
        "Using freqlimits defined with --freqlimits",
        action="store_true",
        default=False,
    )
    beam_parser.add_argument(
        "--fade",
        help="time domain fader applied before restitution" "default=10 seconds",
        type=float,
        default=10.0,
    )
    beam_parser.add_argument(
        "--freqlimits",
        help="Frequency domain tapers for restitution." "default=0.2:0.8:20:40",
        default="0.2:0.8:20:40",
    )
    beam_parser.add_argument(
        "--plot",
        help="create plots showing stations and store them " "in sub-directories",
        action="store_true",
        default=False,
    )

    store_parser = sp.add_parser("stores", help="Propose GF stores")
    store_parser.add_argument(
        "projects", help='default "all available"', nargs="*", default="."
    )
    store_parser.add_argument(
        "--super-dir",
        dest="store_dir",
        help="super directory where to search/create stores. Default: stores",
        default="stores",
    )
    store_parser.add_argument(
        "--depths", help="zmin:zmax:deltaz [km]", default="0:15:1", required=False
    )
    store_parser.add_argument(
        "--sampling-rate",
        dest="sample_rate",
        type=float,
        help="samppling rate store [Hz]. Default 10",
        default=10.0,
    )
    store_parser.add_argument(
        "--force",
        dest="force",
        default=False,
        help="overwrite existent stores",
        action="store_true",
    )
    store_parser.add_argument(
        "--ttt",
        dest="ttt",
        help="also generate travel time tables.",
        action="store_true",
    )
    store_parser.add_argument(
        "--simplify",
        help="Simplify model to increase performance "
        "and in case of QSEIS lmax too small error.",
        action="store_true",
    )
    store_parser.add_argument(
        "--dmax",
        help="maximum of distance delta config file.",
        type=float,
        default=None,
    )
    store_parser.add_argument("--station", help="(Rather for standalone use. Optional)")

    process_parser = sp.add_parser("process", help="Create images")
    process_parser.add_argument(
        "projects", help='default "all available"', nargs="*", default="."
    )
    process_parser.add_argument(
        "--array-id",
        dest="array_id",
        help="array-id to process",
        required=False,
        default=False,
    )
    process_parser.add_argument(
        "--settings", help="settings file", default=False, required=False
    )
    process_parser.add_argument(
        "--cc_align", help="dummy argument at the moment", required=False
    )
    process_parser.add_argument(
        "--store-superdirs",
        help="super directory where to look for stores",
        dest="store_superdirs",
        nargs="*",
        default=["stores"],
        required=False,
    )
    process_parser.add_argument(
        "--store", help="name of store id", dest="store_id", required=False
    )
    process_parser.add_argument(
        "--depth", help="assumed source depth [km]", required=False
    )
    process_parser.add_argument(
        "--depths",
        help="testing depths in km. zstart:zstop:delta, default 0:15:1",
        default="0:15:1",
        required=False,
    )
    process_parser.add_argument(
        "--quantity",
        help="velocity|displacement",
        choices=["velocity", "displacement", "restituted"],
        required=False,
    )
    process_parser.add_argument(
        "--filter", help='4th order butterw. default: "0.7:4.5"', required=False
    )
    process_parser.add_argument(
        "--correction", required=False, help="a global correction in time [s]"
    )
    process_parser.add_argument(
        "--gain", required=False, help="gain factor", default=1.0, type=float
    )
    process_parser.add_argument(
        "--zoom",
        required=False,
        help="time window to look at. default -7:15",
        default="-7:15",
    )

    process_parser.add_argument(
        "--normalize", help="normalize traces to 1", action="store_true", required=False
    )
    process_parser.add_argument(
        "--skip-true",
        help="if true, do not plot recorded and the assigned synthetic trace on top of each other",
        dest="skip_true",
        action="store_true",
        required=False,
    )
    process_parser.add_argument(
        "--show",
        help="show matplotlib plots after each step",
        action="store_true",
        required=False,
    )
    process_parser.add_argument(
        "--force-nearest-neighbor",
        help="handles OOB",
        dest="force_nearest_neighbor",
        default=False,
        action="store_true",
        required=False,
    )
    process_parser.add_argument(
        "--auto-caption",
        help="Add a caption to figure with basic info",
        dest="auto_caption",
        default=False,
        action="store_true",
        required=False,
    )
    process_parser.add_argument(
        "--out-filename", help="file to store image", dest="save_as", required=False
    )
    process_parser.add_argument(
        "--print-parameters",
        dest="print_parameters",
        help="creates a text field giving the used parameters",
        required=False,
    )
    process_parser.add_argument(
        "--title", dest="title", help="template for title.", required=False
    )
    process_parser.add_argument(
        "--overwrite-settings",
        dest="overwrite_settings",
        help="overwrite former settings files",
        default=False,
        action="store_true",
        required=False,
    )

    snuffle_parser = sp.add_parser("snuffle", help="Scrutinize waveforms")
    snuffle_parser.add_argument(
        "projects", help='default "all available"', nargs="*", default="."
    )

    map_parser = sp.add_parser("map", help="Create map")
    map_parser.add_argument(
        "--topography",
        dest="show_topo",
        help="overlay topography",
        default=False,
        action="store_true",
        required=False,
    )

    bounds_parser = sp.add_parser(
        "bounds",
        help="Get bounds of array vs catalog of events. "
        "Helpful when generating stores for entire catalogs.",
    )
    bounds_parser.add_argument("--events", help="events filename", required=True)
    bounds_parser.add_argument("--array-id", dest="array_id", required=True)

    args = parser.parse_args()

    util.setup_logging('abedeto', args.log.lower())

    try:
        if args.cmd == "init":
            init(args)

        elif args.cmd == "download":
            download(args)

        elif args.cmd == "stores":
            propose_stores(args)

        elif args.cmd == "beam":
            beam(args)

        elif args.cmd == "process":
            process(args)

        elif args.cmd == "bounds":
            get_bounds(args)

        elif args.cmd == "map":
            mapify(args)

        elif args.cmd == "snuffle":
            snuffle(args)

        else:
            parser.print_help()

    except CannotCreate as e:
        logger.error("%s. Run with --force to overwrite existing data." % e)
